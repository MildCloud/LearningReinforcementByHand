{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "import gym\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class CEM:\n",
    "    def __init__(self, n_sequence, elite_ratio, fake_env, upper_bound, lower_bound):\n",
    "        self.n_sequence = n_sequence\n",
    "        self.elite_ratio = elite_ratio\n",
    "        self.upper_bound = upper_bound\n",
    "        self.lower_bound = lower_bound\n",
    "        self.fake_env = fake_env\n",
    "\n",
    "    def optimize(self, state, init_mean, init_var):\n",
    "        mean, var = init_mean, init_var\n",
    "        # mean.shape (25,)\n",
    "        X = truncnorm(-2, 2, loc=np.zeros_like(mean), scale=np.ones_like(var))\n",
    "        # env.action_space.low[0] = -2, env.action_space.high[0] = 2\n",
    "        state = np.tile(state, (self.n_sequence, 1))\n",
    "        # truncnorm ? labels = np.concatenate((rewards, next_obs - obs), axis=-1) Class PETS line 25\n",
    "        # print('state.shape', state.shape)\n",
    "        # state.shape (50, 3)\n",
    "        # copy the state into shape(50, 3)\n",
    "\n",
    "        for _ in range(5):\n",
    "            lb_dist, ub_dist = mean - self.lower_bound, self.upper_bound - mean\n",
    "            constrained_var = np.minimum(np.minimum(np.square(lb_dist / 2), np.square(ub_dist / 2)), var)\n",
    "            # 生成动作序列\n",
    "            action_sequences = [X.rvs() for _ in range(self.n_sequence)] * np.sqrt(constrained_var) + mean\n",
    "            # print('action_sequences.shape', action_sequences.shape)\n",
    "            # action_sequences.shape (50, 25)\n",
    "            # 计算每条动作序列的累积奖励\n",
    "            returns = self.fake_env.propagate(state, action_sequences)[:, 0]\n",
    "            # print('returns.shape', returns.shape)\n",
    "            # returns.shape (50,)\n",
    "            # 选取累积奖励最高的若干条动作序列\n",
    "            elites = action_sequences[np.argsort(returns)][-int(self.elite_ratio * self.n_sequence):]\n",
    "            # print('elites.shape', elites.shape)\n",
    "            # elites.shape (10, 25)\n",
    "            new_mean = np.mean(elites, axis=0)\n",
    "            new_var = np.var(elites, axis=0)\n",
    "            # 更新动作序列分布\n",
    "            mean = 0.1 * mean + 0.9 * new_mean\n",
    "            var = 0.1 * var + 0.9 * new_var\n",
    "\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\n",
    "    \"cpu\")\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    ''' Swish激活函数 '''\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    ''' 初始化模型权重 '''\n",
    "    def truncated_normal_init(t, mean=0.0, std=0.01):\n",
    "        torch.nn.init.normal_(t, mean=mean, std=std)\n",
    "        while True:\n",
    "            cond = (t < mean - 2 * std) | (t > mean + 2 * std)\n",
    "            if not torch.sum(cond):\n",
    "                break\n",
    "            t = torch.where(cond, torch.nn.init.normal_(torch.ones(t.shape, device=device), mean=mean, std=std), t)\n",
    "        return t\n",
    "\n",
    "    if type(m) == nn.Linear or isinstance(m, FCLayer):\n",
    "        truncated_normal_init(m.weight, std=1 / (2 * np.sqrt(m._input_dim)))\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "class FCLayer(nn.Module):\n",
    "    ''' 集成之后的全连接层 '''\n",
    "    # The difference between the nn.Linear and this customized FCLayer is that this layer have different parameters for different batch\n",
    "    def __init__(self, input_dim, output_dim, ensemble_size, activation):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self._input_dim, self._output_dim = input_dim, output_dim\n",
    "        self.weight = nn.Parameter(torch.Tensor(ensemble_size, input_dim, output_dim).to(device))\n",
    "        self._activation = activation\n",
    "        self.bias = nn.Parameter(torch.Tensor(ensemble_size, output_dim).to(device))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # output = self._activation(torch.add(torch.bmm(x, self.weight), self.bias[:, None, :]))\n",
    "        # print('output.shape', output.shape)\n",
    "        # output.shape torch.Size([5, 64, 200])\n",
    "        # output.shape torch.Size([5, 64, 8])\n",
    "        return self._activation(torch.add(torch.bmm(x, self.weight), self.bias[:, None, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    ''' 环境模型集成 '''\n",
    "    def __init__(self, state_dim, action_dim, ensemble_size=5, learning_rate=1e-3):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        # 输出包括均值和方差,因此是状态与奖励维度之和的两倍\n",
    "        # The output is the mean and variance of the state and action\n",
    "        self._output_dim = (state_dim + 1) * 2\n",
    "        self._max_logvar = nn.Parameter((torch.ones((1, self._output_dim // 2)).float() / 2).to(device), requires_grad=False)\n",
    "        self._min_logvar = nn.Parameter((-torch.ones( (1, self._output_dim // 2)).float() * 10).to(device), requires_grad=False)\n",
    "\n",
    "        self.layer1 = FCLayer(state_dim + action_dim, 200, ensemble_size, Swish())\n",
    "        self.layer2 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer3 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer4 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer5 = FCLayer(200, self._output_dim, ensemble_size, nn.Identity())\n",
    "        self.apply(init_weights)  # 初始化环境模型中的参数\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x, return_log_var=False):\n",
    "        # print('x.shape', x.shape)\n",
    "        # x.shape torch.Size([5, 64, 4]) x.shape torch.Size([5, 52, 4]) x.shape torch.Size([5, 20, 4]) 64 * 2 + 52 + 20 = 200\n",
    "        ret = self.layer5(self.layer4(self.layer3(self.layer2(self.layer1(x)))))\n",
    "        # print('ret.shape', ret.shape)\n",
    "        # ret.shape torch.Size([5, 64, 8]) ...\n",
    "        mean = ret[:, :, :self._output_dim // 2]\n",
    "        # 在PETS算法中,将方差控制在最小值和最大值之间\n",
    "        logvar = self._max_logvar - F.softplus(self._max_logvar - ret[:, :, self._output_dim // 2:])\n",
    "        logvar = self._min_logvar + F.softplus(logvar - self._min_logvar)\n",
    "        return mean, logvar if return_log_var else torch.exp(logvar)\n",
    "\n",
    "    def loss(self, mean, logvar, labels, use_var_loss=True):\n",
    "        inverse_var = torch.exp(-logvar)\n",
    "        if use_var_loss:\n",
    "            mse_loss = torch.mean(torch.mean(torch.pow(mean - labels, 2) * inverse_var, dim=-1), dim=-1)\n",
    "            var_loss = torch.mean(torch.mean(logvar, dim=-1), dim=-1)\n",
    "            # compute the mean across two dimension for both mse_loss and var_loss, the output shape is (5, )\n",
    "            total_loss = torch.sum(mse_loss) + torch.sum(var_loss)\n",
    "        else:\n",
    "            mse_loss = torch.mean(torch.pow(mean - labels, 2), dim=(1, 2))\n",
    "            total_loss = torch.sum(mse_loss)\n",
    "        return total_loss, mse_loss\n",
    "\n",
    "    def train(self, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss += 0.01 * torch.sum(self._max_logvar) - 0.01 * torch.sum(self._min_logvar)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleDynamicsModel:\n",
    "    ''' 环境模型集成,加入精细化的训练 '''\n",
    "    def __init__(self, state_dim, action_dim, num_network=5):\n",
    "        self._num_network = num_network\n",
    "        self._state_dim, self._action_dim = state_dim, action_dim\n",
    "        self.model = EnsembleModel(state_dim, action_dim, ensemble_size=num_network)\n",
    "        self._epoch_since_last_update = 0\n",
    "\n",
    "    def train(self, inputs, labels, batch_size=64, holdout_ratio=0.1, max_iter=20):\n",
    "        # 设置训练集与验证集\n",
    "        # print('inputs.shape', inputs.shape, 'labels.shape', labels.shape)\n",
    "        # inputs.shape (200 * (num_episode - 1), 4) labels.shape (200 * (num_episode - 1), 4)\n",
    "        permutation = np.random.permutation(inputs.shape[0])\n",
    "        inputs, labels = inputs[permutation], labels[permutation]\n",
    "        # shuffle the inputs and labels with the same random permutation\n",
    "        # not change the shape of inputs and labels\n",
    "        num_holdout = int(inputs.shape[0] * holdout_ratio)\n",
    "        train_inputs, train_labels = inputs[num_holdout:], labels[num_holdout:]\n",
    "        holdout_inputs, holdout_labels = inputs[:num_holdout], labels[:num_holdout]\n",
    "        holdout_inputs = torch.from_numpy(holdout_inputs).float().to(device)\n",
    "        holdout_labels = torch.from_numpy(holdout_labels).float().to(device)\n",
    "        holdout_inputs = holdout_inputs[None, :, :].repeat([self._num_network, 1, 1])\n",
    "        holdout_labels = holdout_labels[None, :, :].repeat([self._num_network, 1, 1])\n",
    "\n",
    "        # 保留最好的结果\n",
    "        self._snapshots = {i: (None, 1e10) for i in range(self._num_network)}\n",
    "\n",
    "        for epoch in itertools.count():\n",
    "            # 定义每一个网络的训练数据\n",
    "            train_index = np.vstack([np.random.permutation(train_inputs.shape[0]) for _ in range(self._num_network)])\n",
    "            # 所有真实数据都用来训练\n",
    "            for batch_start_pos in range(0, train_inputs.shape[0], batch_size):\n",
    "                batch_index = train_index[:, batch_start_pos:batch_start_pos + batch_size]\n",
    "                train_input = torch.from_numpy(train_inputs[batch_index]).float().to(device)\n",
    "                train_label = torch.from_numpy(train_labels[batch_index]).float().to(device)\n",
    "                mean, logvar = self.model(train_input, return_log_var=True)\n",
    "                loss, _ = self.model.loss(mean, logvar, train_label)\n",
    "                self.model.train(loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                mean, logvar = self.model(holdout_inputs, return_log_var=True)\n",
    "                _, holdout_losses = self.model.loss(mean, logvar, holdout_labels, use_var_loss=False)\n",
    "                holdout_losses = holdout_losses.cpu()\n",
    "                break_condition = self._save_best(epoch, holdout_losses)\n",
    "                if break_condition or epoch > max_iter:  # 结束训练\n",
    "                    break\n",
    "\n",
    "    def _save_best(self, epoch, losses, threshold=0.1):\n",
    "        updated = False\n",
    "        for i in range(len(losses)):\n",
    "            current = losses[i]\n",
    "            _, best = self._snapshots[i]\n",
    "            improvement = (best - current) / best\n",
    "            if improvement > threshold:\n",
    "                self._snapshots[i] = (epoch, current)\n",
    "                updated = True\n",
    "        self._epoch_since_last_update = 0 if updated else self._epoch_since_last_update + 1\n",
    "        return self._epoch_since_last_update > 5\n",
    "\n",
    "    def predict(self, inputs, batch_size=64):\n",
    "        mean, var = [], []\n",
    "        for i in range(0, inputs.shape[0], batch_size):\n",
    "            input = torch.from_numpy(inputs[i:min(i + batch_size, inputs.shape[0])]).float().to(device)\n",
    "            cur_mean, cur_var = self.model(input[None, :, :].repeat([self._num_network, 1, 1]), return_log_var=False)\n",
    "            # print('cur_mean.shape', cur_mean.shape, 'cur_var.shape', cur_var.shape)\n",
    "            # cur_mean.shape torch.Size([5, 50, 4]) cur_var.shape torch.Size([5, 50, 4]) 50 = n_sequence\n",
    "            mean.append(cur_mean.detach().cpu().numpy())\n",
    "            var.append(cur_var.detach().cpu().numpy())\n",
    "        return np.hstack(mean), np.hstack(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeEnv:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def step(self, obs, act):\n",
    "        inputs = np.concatenate((obs, act), axis=-1)\n",
    "        # print('step inputs.shape', inputs.shape)\n",
    "        # (n_sequence, 4)\n",
    "        ensemble_model_means, ensemble_model_vars = self.model.predict(inputs)\n",
    "        ensemble_model_means[:, :, 1:] += obs.numpy()\n",
    "        # ?\n",
    "        ensemble_model_stds = np.sqrt(ensemble_model_vars)\n",
    "        ensemble_samples = ensemble_model_means + np.random.normal(size=ensemble_model_means.shape) * ensemble_model_stds\n",
    "\n",
    "        num_models, batch_size, _ = ensemble_model_means.shape\n",
    "        # print('ensemble_model_means.shape', ensemble_model_means.shape)\n",
    "        # ensemble_model_means.shape (5, 50, 4)\n",
    "        models_to_use = np.random.choice([i for i in range(self.model._num_network)], size=batch_size)\n",
    "        batch_inds = np.arange(0, batch_size)\n",
    "        # randomly choose the model prediction of the next state\n",
    "        samples = ensemble_samples[models_to_use, batch_inds]\n",
    "        # print('samples.shape', samples.shape)\n",
    "        # samples.shape (50, 4) 50 = n_sequence\n",
    "        rewards, next_obs = samples[:, :1], samples[:, 1:]\n",
    "        return rewards, next_obs\n",
    "\n",
    "    def propagate(self, obs, actions):\n",
    "        with torch.no_grad():\n",
    "            obs = np.copy(obs)\n",
    "            total_reward = np.expand_dims(np.zeros(obs.shape[0]), axis=-1)\n",
    "            # print('total_reward.shape', total_reward.shape)\n",
    "            # total_reward.shape (50, 1)\n",
    "            obs, actions = torch.as_tensor(obs), torch.as_tensor(actions)\n",
    "            # actions.shape = action_sequences.shape (50, 25) plan_horizon = 25 with action_dim = 1\n",
    "            # 50 policy, each policy plan for 25 / 1 = 25 steps, and calculate the total reward\n",
    "            for i in range(actions.shape[1]):\n",
    "                action = torch.unsqueeze(actions[:, i], 1)\n",
    "                # add one dimension to dimension 1\n",
    "                rewards, next_obs = self.step(obs, action)\n",
    "                total_reward += rewards\n",
    "                obs = torch.as_tensor(next_obs)\n",
    "            return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def return_all_samples(self):\n",
    "        all_transitions = list(self.buffer)\n",
    "        state, action, reward, next_state, done = zip(*all_transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PETS:\n",
    "    ''' PETS算法 '''\n",
    "    def __init__(self, env, replay_buffer, n_sequence, elite_ratio, plan_horizon, num_episodes):\n",
    "        self._env = env\n",
    "        self._env_pool = replay_buffer\n",
    "\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        self._action_dim = env.action_space.shape[0]\n",
    "        self._model = EnsembleDynamicsModel(obs_dim, self._action_dim)\n",
    "        self._fake_env = FakeEnv(self._model)\n",
    "        self.upper_bound = env.action_space.high[0]\n",
    "        self.lower_bound = env.action_space.low[0]\n",
    "\n",
    "        self._cem = CEM(n_sequence, elite_ratio, self._fake_env, self.upper_bound, self.lower_bound)\n",
    "        self.plan_horizon = plan_horizon\n",
    "        self.num_episodes = num_episodes\n",
    "\n",
    "    def train_model(self):\n",
    "        env_samples = self._env_pool.return_all_samples()\n",
    "        obs = env_samples[0]\n",
    "        actions = np.array(env_samples[1])\n",
    "        rewards = np.array(env_samples[2]).reshape(-1, 1)\n",
    "        next_obs = env_samples[3]\n",
    "        inputs = np.concatenate((obs, actions), axis=-1)\n",
    "        labels = np.concatenate((rewards, next_obs - obs), axis=-1)\n",
    "        self._model.train(inputs, labels)\n",
    "\n",
    "    def mpc(self):\n",
    "        mean = np.tile((self.upper_bound + self.lower_bound) / 2.0, self.plan_horizon)\n",
    "        var = np.tile(np.square(self.upper_bound - self.lower_bound) / 16, self.plan_horizon)\n",
    "        # print('mean.shape', mean.shape, 'var.shape', var.shape)\n",
    "        # mean.shape (25,) var.shape (25,)\n",
    "        obs, done, episode_return = self._env.reset(), False, 0\n",
    "        # obs.shape = [state_dim = 3]\n",
    "        while not done:\n",
    "            actions = self._cem.optimize(obs, mean, var)\n",
    "            action = actions[:self._action_dim]  # 选取第一个动作\n",
    "            next_obs, reward, done, _ = self._env.step(action)\n",
    "            self._env_pool.add(obs, action, reward, next_obs, done)\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "            mean = np.concatenate([\n",
    "                np.copy(actions)[self._action_dim:],\n",
    "                np.zeros(self._action_dim)\n",
    "            ])\n",
    "            # mean.shape (25,) self.plan_horizon = 25\n",
    "        return episode_return\n",
    "\n",
    "    def explore(self):\n",
    "        obs, done, episode_return = self._env.reset(), False, 0\n",
    "        while not done:\n",
    "            action = self._env.action_space.sample()\n",
    "            next_obs, reward, done, _ = self._env.step(action)\n",
    "            self._env_pool.add(obs, action, reward, next_obs, done)\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "        return episode_return\n",
    "\n",
    "    def train(self):\n",
    "        return_list = []\n",
    "        explore_return = self.explore()  # 先进行随机策略的探索来收集一条序列的数据\n",
    "        print('episode: 1, return: %d' % explore_return)\n",
    "        return_list.append(explore_return)\n",
    "\n",
    "        for i_episode in range(self.num_episodes - 1):\n",
    "            self.train_model()\n",
    "            episode_return = self.mpc()\n",
    "            return_list.append(episode_return)\n",
    "            print('episode: %d, return: %d' % (i_episode + 2, episode_return))\n",
    "        return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1, return: -1296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n",
      "returns.shape (50,)\n",
      "elites.shape (10, 25)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m replay_buffer \u001b[39m=\u001b[39m ReplayBuffer(buffer_size)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m pets \u001b[39m=\u001b[39m PETS(env, replay_buffer, n_sequence, elite_ratio, plan_horizon, num_episodes)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m return_list \u001b[39m=\u001b[39m pets\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m episodes_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(return_list)))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(episodes_list, return_list)\n",
      "\u001b[1;32m/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mfor\u001b[39;00m i_episode \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_episodes \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_model()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m     episode_return \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmpc()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m     return_list\u001b[39m.\u001b[39mappend(episode_return)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mepisode: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, return: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (i_episode \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m, episode_return))\n",
      "\u001b[1;32m/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# obs.shape = [state_dim = 3]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cem\u001b[39m.\u001b[39;49moptimize(obs, mean, var)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     action \u001b[39m=\u001b[39m actions[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action_dim]  \u001b[39m# 选取第一个动作\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     next_obs, reward, done, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_env\u001b[39m.\u001b[39mstep(action)\n",
      "\u001b[1;32m/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m action_sequences \u001b[39m=\u001b[39m [X\u001b[39m.\u001b[39mrvs() \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_sequence)] \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msqrt(constrained_var) \u001b[39m+\u001b[39m mean\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# print('action_sequences.shape', action_sequences.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# action_sequences.shape (50, 25)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# 计算每条动作序列的累积奖励\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m returns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfake_env\u001b[39m.\u001b[39;49mpropagate(state, action_sequences)[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mreturns.shape\u001b[39m\u001b[39m'\u001b[39m, returns\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# 选取累积奖励最高的若干条动作序列\u001b[39;00m\n",
      "\u001b[1;32m/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m action \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(actions[:, i], \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# add one dimension to dimension 1\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m rewards, next_obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep(obs, action)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m total_reward \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m rewards\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m obs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(next_obs)\n",
      "\u001b[1;32m/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m inputs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((obs, act), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# print('step inputs.shape', inputs.shape)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# (n_sequence, 4)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m ensemble_model_means, ensemble_model_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m ensemble_model_means[:, :, \u001b[39m1\u001b[39m:] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m obs\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m ensemble_model_stds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(ensemble_model_vars)\n",
      "\u001b[1;32m/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, inputs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], batch_size):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(inputs[i:\u001b[39mmin\u001b[39m(i \u001b[39m+\u001b[39m batch_size, inputs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])])\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m     cur_mean, cur_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39minput\u001b[39;49m[\u001b[39mNone\u001b[39;49;00m, :, :]\u001b[39m.\u001b[39;49mrepeat([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_network, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m]), return_log_var\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39m# print('cur_mean.shape', cur_mean.shape, 'cur_var.shape', cur_var.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m     \u001b[39m# cur_mean.shape torch.Size([5, 50, 4]) cur_var.shape torch.Size([5, 50, 4]) 50 = n_sequence\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m     mean\u001b[39m.\u001b[39mappend(cur_mean\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, return_log_var\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m# print('x.shape', x.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# x.shape torch.Size([5, 64, 4]) x.shape torch.Size([5, 52, 4]) x.shape torch.Size([5, 20, 4]) 64 * 2 + 52 + 20 = 200\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer5(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer4(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(x)))))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# print('ret.shape', ret.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# ret.shape torch.Size([5, 64, 8]) ...\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tianshu/LearningReinforcementByHand/15-MPC/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     mean \u001b[39m=\u001b[39m ret[:, :, :\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_dim \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1192\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m forward_call \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state() \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward)\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m-> 1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m   1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "buffer_size = 100000\n",
    "n_sequence = 50\n",
    "elite_ratio = 0.2\n",
    "plan_horizon = 25\n",
    "num_episodes = 2\n",
    "env_name = 'Pendulum-v1'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "replay_buffer = ReplayBuffer(buffer_size)\n",
    "pets = PETS(env, replay_buffer, n_sequence, elite_ratio, plan_horizon, num_episodes)\n",
    "return_list = pets.train()\n",
    "\n",
    "episodes_list = list(range(len(return_list)))\n",
    "plt.plot(episodes_list, return_list)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('PETS on {}'.format(env_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 8.9683e-44,  0.0000e+00,  4.6243e-44],\n",
      "         [ 0.0000e+00, -1.3140e-03,  0.0000e+00],\n",
      "         [-3.7788e-03,  0.0000e+00,  1.3452e-43]],\n",
      "\n",
      "        [[ 8.9683e-44,  0.0000e+00,  4.6243e-44],\n",
      "         [ 0.0000e+00, -1.3140e-03,  0.0000e+00],\n",
      "         [-3.7788e-03,  0.0000e+00,  1.3452e-43]],\n",
      "\n",
      "        [[ 8.9683e-44,  0.0000e+00,  4.6243e-44],\n",
      "         [ 0.0000e+00, -1.3140e-03,  0.0000e+00],\n",
      "         [-3.7788e-03,  0.0000e+00,  1.3452e-43]]])\n",
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.],\n",
      "         [12., 13., 14.],\n",
      "         [15., 16., 17.]],\n",
      "\n",
      "        [[18., 19., 20.],\n",
      "         [21., 22., 23.],\n",
      "         [24., 25., 26.]]])\n",
      "c [2 0 1]\n",
      "d [0 1 2]\n",
      "tensor([[18., 19., 20.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [15., 16., 17.]])\n",
      "[[3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "test_net = nn.Linear(3, 10)\n",
    "b = torch.arange(0, 27, dtype=torch.float32).reshape(3, 3, 3)\n",
    "a = torch.Tensor(3, 3)\n",
    "print(a[None, :, :].repeat(3, 1, 1))\n",
    "print(b)\n",
    "c = np.random.choice([i for i in range(3)], size=3)\n",
    "d = np.arange(0, 3)\n",
    "print('c', c)\n",
    "print('d', d)\n",
    "print(b[c, d])\n",
    "print(np.array([[2]]) + np.array([[1, 2, 3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n",
      "[1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
      "{'a': 10}\n",
      "(1, 2, 3)\n",
      "[10 20 30]\n",
      "tensor([10, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        self.a = 1\n",
    "\n",
    "def func_test(ca):\n",
    "    ca.a = 10\n",
    "\n",
    "def func_test2(a):\n",
    "    a *=  10\n",
    "\n",
    "def func_test3(ca):\n",
    "    ca['a'] = 10\n",
    "\n",
    "ca = test()\n",
    "print(ca.a)\n",
    "func_test(ca)\n",
    "print(ca.a)\n",
    "a = [1, 2, 3]\n",
    "func_test2(a)\n",
    "print(a)\n",
    "a = {'a': 19}\n",
    "func_test3(a)\n",
    "print(a)\n",
    "a = (1, 2, 3)\n",
    "func_test2(a)\n",
    "print(a)\n",
    "a = np.array([1, 2, 3])\n",
    "func_test2(a)\n",
    "print(a)\n",
    "a = torch.tensor([1, 2, 3])\n",
    "func_test2(a)\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
